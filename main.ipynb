{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d459ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:31.461855Z",
     "iopub.status.busy": "2024-05-14T15:43:31.461470Z",
     "iopub.status.idle": "2024-05-14T15:43:35.833485Z",
     "shell.execute_reply": "2024-05-14T15:43:35.832552Z"
    },
    "papermill": {
     "duration": 4.380851,
     "end_time": "2024-05-14T15:43:35.835934",
     "exception": false,
     "start_time": "2024-05-14T15:43:31.455083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cd4c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:35.846192Z",
     "iopub.status.busy": "2024-05-14T15:43:35.845683Z",
     "iopub.status.idle": "2024-05-14T15:43:35.851405Z",
     "shell.execute_reply": "2024-05-14T15:43:35.850611Z"
    },
    "papermill": {
     "duration": 0.013442,
     "end_time": "2024-05-14T15:43:35.853837",
     "exception": false,
     "start_time": "2024-05-14T15:43:35.840395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "CONTEXT_SIZE = 256\n",
    "TRANSFORMER_COUNT = 6\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e41d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:35.863612Z",
     "iopub.status.busy": "2024-05-14T15:43:35.863268Z",
     "iopub.status.idle": "2024-05-14T15:43:36.324683Z",
     "shell.execute_reply": "2024-05-14T15:43:36.323261Z"
    },
    "papermill": {
     "duration": 0.468867,
     "end_time": "2024-05-14T15:43:36.326977",
     "exception": false,
     "start_time": "2024-05-14T15:43:35.858110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours !\n",
       "2                    Run!               Courez !\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             Ça alors !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4f439c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:36.337478Z",
     "iopub.status.busy": "2024-05-14T15:43:36.337100Z",
     "iopub.status.idle": "2024-05-14T15:43:37.022035Z",
     "shell.execute_reply": "2024-05-14T15:43:37.020942Z"
    },
    "papermill": {
     "duration": 0.692332,
     "end_time": "2024-05-14T15:43:37.023870",
     "exception": false,
     "start_time": "2024-05-14T15:43:36.331538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi.', 'run!', 'run!', 'who?', 'wow!']\n",
      "['salut!', 'cours!', 'courez!', 'qui ?', 'ça alors!']\n"
     ]
    }
   ],
   "source": [
    "english_all = df[\"English words/sentences\"].values.astype(str)\n",
    "french_all = df[\"French words/sentences\"].values.astype(str)\n",
    "\n",
    "english_all = [seq.replace(\"\\u202f\", \"\") for seq in english_all]\n",
    "french_all = [seq.replace(\"\\u202f\", \"\") for seq in french_all]\n",
    "\n",
    "english_all = [seq.lower() for seq in english_all]\n",
    "french_all = [seq.lower() for seq in french_all]\n",
    "\n",
    "print(english_all[0:5])\n",
    "print(french_all[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cf78e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:37.035274Z",
     "iopub.status.busy": "2024-05-14T15:43:37.034838Z",
     "iopub.status.idle": "2024-05-14T15:43:37.083082Z",
     "shell.execute_reply": "2024-05-14T15:43:37.081833Z"
    },
    "papermill": {
     "duration": 0.05695,
     "end_time": "2024-05-14T15:43:37.085450",
     "exception": false,
     "start_time": "2024-05-14T15:43:37.028500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding token ID for english: -1\n",
      "Padding token ID for frencb: -1\n",
      "EN Vocab Size:  10000\n",
      "FR Vocab Size:  10000\n"
     ]
    }
   ],
   "source": [
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"/kaggle/input/french-english-tokenization/other/100embed/1/en.wiki.bpe.vs10000.model\")\n",
    "\n",
    "sp_fr = spm.SentencePieceProcessor()\n",
    "sp_fr.load(\"/kaggle/input/french-english-tokenization/other/100embed/1/fr.wiki.bpe.vs10000.model\")\n",
    "\n",
    "en_vocab = sp_en.get_piece_size()\n",
    "fr_vocab = sp_fr.get_piece_size()\n",
    "\n",
    "padding_token_id_en = sp_en.pad_id()\n",
    "print(\"Padding token ID for english:\", padding_token_id_en)\n",
    "\n",
    "padding_token_id_fr = sp_fr.pad_id()\n",
    "print(\"Padding token ID for frencb:\", padding_token_id_fr)\n",
    "\n",
    "\n",
    "print(\"EN Vocab Size: \", en_vocab)\n",
    "print(\"FR Vocab Size: \", fr_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2355f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:37.096881Z",
     "iopub.status.busy": "2024-05-14T15:43:37.096520Z",
     "iopub.status.idle": "2024-05-14T15:43:44.689395Z",
     "shell.execute_reply": "2024-05-14T15:43:44.687691Z"
    },
    "papermill": {
     "duration": 7.601366,
     "end_time": "2024-05-14T15:43:44.692028",
     "exception": false,
     "start_time": "2024-05-14T15:43:37.090662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 40, 9916, 9935, 2], [1, 888, 9960, 2], [1, 888, 9960, 2], [1, 305, 9967, 2], [1, 15, 90, 9960, 2]]\n",
      "[[1, 1021, 138, 9977, 2], [1, 926, 9977, 2], [1, 844, 6607, 9977, 2], [1, 135, 2340, 2], [1, 9558, 494, 9977, 2]]\n"
     ]
    }
   ],
   "source": [
    "english_data = [sp_en.encode_as_ids(seq) for seq in english_all]\n",
    "french_data = [sp_fr.encode_as_ids(seq) for seq in french_all]\n",
    "\n",
    "english_data = [[sp_en.piece_to_id(\"<s>\")] + seq + [sp_en.piece_to_id(\"</s>\")] for seq in english_data]\n",
    "french_data = [[sp_fr.piece_to_id(\"<s>\")] + seq + [sp_fr.piece_to_id(\"</s>\")] for seq in french_data]\n",
    "\n",
    "print(english_data[0:5])\n",
    "print(french_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984a1e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.703160Z",
     "iopub.status.busy": "2024-05-14T15:43:44.702784Z",
     "iopub.status.idle": "2024-05-14T15:43:44.712382Z",
     "shell.execute_reply": "2024-05-14T15:43:44.711562Z"
    },
    "papermill": {
     "duration": 0.017313,
     "end_time": "2024-05-14T15:43:44.714104",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.696791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Single Attention Head\n",
    "class SingleHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, head_size, context_size:int, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, masked=True, cross=None):\n",
    "        B,T, C = x.shape\n",
    "        \n",
    "        if cross is None:\n",
    "            k = self.key(x)   # Size (B, T, head_size)\n",
    "            v = self.value(x) # same thing..\n",
    "        else:\n",
    "            k = cross.detach().clone()\n",
    "            v = cross.detach().clone()\n",
    "            \n",
    "        \n",
    "        q = self.query(x) # same thing..\n",
    "        \n",
    "        weight = q @ k.transpose(-2, -1) * (k.shape[-1]**-0.5) # this equation is defined in the original paper and the multiplication part is normalization over each Time Serie in the batch.\n",
    "        if(masked): weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) # This will mask the upper triangle of zeros and turn it into -inf for the softmax func\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        weight = self.dropout(weight)\n",
    "\n",
    "        v = self.value(x)\n",
    "        \n",
    "        out = weight @ v\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e322dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.724614Z",
     "iopub.status.busy": "2024-05-14T15:43:44.724226Z",
     "iopub.status.idle": "2024-05-14T15:43:44.732404Z",
     "shell.execute_reply": "2024-05-14T15:43:44.731155Z"
    },
    "papermill": {
     "duration": 0.01595,
     "end_time": "2024-05-14T15:43:44.734502",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.718552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, num_heads, head_size, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SingleHeadedAttention(embed_size,head_size, context_size, dropout) for _ in range(num_heads)])\n",
    "        self.linear = nn.Linear(head_size*num_heads, embed_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, cross=None):\n",
    "        if cross is not None:\n",
    "            B, T, _ = cross.shape\n",
    "            cross = cross.view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
    "        \n",
    "        out = torch.cat([h(x, masked, cross[:, i] if cross is not None else None) for i, h in enumerate(self.heads)], dim=-1)\n",
    "\n",
    "        out = self.linear(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acac160c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.745457Z",
     "iopub.status.busy": "2024-05-14T15:43:44.745054Z",
     "iopub.status.idle": "2024-05-14T15:43:44.751123Z",
     "shell.execute_reply": "2024-05-14T15:43:44.750271Z"
    },
    "papermill": {
     "duration": 0.014359,
     "end_time": "2024-05-14T15:43:44.753584",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.739225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Linear(emb_size, emb_size*4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(emb_size*4, emb_size),\n",
    "        nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e75ea09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.764698Z",
     "iopub.status.busy": "2024-05-14T15:43:44.764290Z",
     "iopub.status.idle": "2024-05-14T15:43:44.771366Z",
     "shell.execute_reply": "2024-05-14T15:43:44.769979Z"
    },
    "papermill": {
     "duration": 0.015114,
     "end_time": "2024-05-14T15:43:44.773520",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.758406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderTransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        head_size = embed_size // num_heads\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_norm1 = self.norm1(x)\n",
    "        x = x + self.attention(x_norm1, masked=True)\n",
    "        x_norm2 = self.norm2(x)\n",
    "        x = x + self.ff(x_norm2)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664a0959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.784776Z",
     "iopub.status.busy": "2024-05-14T15:43:44.784369Z",
     "iopub.status.idle": "2024-05-14T15:43:44.793121Z",
     "shell.execute_reply": "2024-05-14T15:43:44.791870Z"
    },
    "papermill": {
     "duration": 0.017625,
     "end_time": "2024-05-14T15:43:44.795791",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.778166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        head_size = embed_size // num_heads\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.self_attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.cross_attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm3 = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, dropout)\n",
    "        \n",
    "    def forward(self, decoder_input, encoder_output):\n",
    "        \n",
    "        dec_norm1 = self.norm1(decoder_input)\n",
    "        self_atten_out = self.self_attention(self.dec_norm1)\n",
    "        dec_out_1 = decoder_input + self_atten_out\n",
    "        \n",
    "        dec_norm_2 = self.norm2(dec_out_1)\n",
    "        cross_atten_out = self.cross_attention(dec_norm_2, cross=encoder_output)\n",
    "        dec_out_2 = dec_out_1 + cross_atten_out\n",
    "        \n",
    "        dec_out = dec_out_2 + self.ff(dec_out_2)\n",
    "        \n",
    "        return dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56650366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.806757Z",
     "iopub.status.busy": "2024-05-14T15:43:44.806354Z",
     "iopub.status.idle": "2024-05-14T15:43:44.814687Z",
     "shell.execute_reply": "2024-05-14T15:43:44.813088Z"
    },
    "papermill": {
     "duration": 0.016809,
     "end_time": "2024-05-14T15:43:44.817328",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.800519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,transformer_count , vocab_size, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embed = nn.Embedding(context_size, embed_size)\n",
    "        self.transformers = nn.Sequential(*[EncoderTransformerBlock(embed_size, num_heads, context_size, dropout=0.2) for _ in range(transformer_count)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        \n",
    "        tk_emb = self.token_embed(x)\n",
    "        pos_emb = self.pos_embed(x)\n",
    "        \n",
    "        x = tk_emb + pos_emb\n",
    "        x = self.transformers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2e6177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.829097Z",
     "iopub.status.busy": "2024-05-14T15:43:44.828735Z",
     "iopub.status.idle": "2024-05-14T15:43:44.836290Z",
     "shell.execute_reply": "2024-05-14T15:43:44.834751Z"
    },
    "papermill": {
     "duration": 0.016695,
     "end_time": "2024-05-14T15:43:44.838753",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.822058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, transformer_count, vocab_size, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embed = nn.Embedding(context_size, embed_size)\n",
    "        self.transformers = nn.Sequential(*[DecoderTransformerBlock(embed_size, num_heads, context_size, dropout)])\n",
    "    \n",
    "    def forward(self, decoder_input, encoder_output):\n",
    "        \n",
    "        B, T = x.shape\n",
    "        \n",
    "        tk_emb = self.token_embed(decoder_input)\n",
    "        pos_emb = self.pos_embed(decoder_input)\n",
    "        \n",
    "        x = tk_emb + pos_emb\n",
    "        \n",
    "        x = self.transformers(x, encoder_output)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5445dda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.850211Z",
     "iopub.status.busy": "2024-05-14T15:43:44.849853Z",
     "iopub.status.idle": "2024-05-14T15:43:44.857795Z",
     "shell.execute_reply": "2024-05-14T15:43:44.856238Z"
    },
    "papermill": {
     "duration": 0.016533,
     "end_time": "2024-05-14T15:43:44.860382",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.843849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FrenchEnglishTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, transformer_count , vocab_size_en, vocab_size_fr, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(transformer_count, vocab_size_fr, embed_size, num_heads, context_size, dropout)\n",
    "        self.decoder = Decoder(transformer_count, vocab_size_en, embed_size, num_heads, context_size, dropout)\n",
    "        self.norm_final = nn.LayerNorm(embed_size)\n",
    "        self.linear_final = nn.Linear(embed_size, vocab_size_en)\n",
    "        \n",
    "    def forward(self, french, english, target_english=None):\n",
    "        \n",
    "        encoder_out = self.encoder(french)\n",
    "        decoder_out = self.decoder(english, encoder_out)\n",
    "        \n",
    "        out = self.norm_final(decoder_out)\n",
    "        out = self.linear_final(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1df7046c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T15:43:44.870984Z",
     "iopub.status.busy": "2024-05-14T15:43:44.870630Z",
     "iopub.status.idle": "2024-05-14T15:43:45.020588Z",
     "shell.execute_reply": "2024-05-14T15:43:45.019330Z"
    },
    "papermill": {
     "duration": 0.157649,
     "end_time": "2024-05-14T15:43:45.022660",
     "exception": false,
     "start_time": "2024-05-14T15:43:44.865011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.366928 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = FrenchEnglishTransformer(TRANSFORMER_COUNT, en_vocab, fr_vocab, EMBEDDING_SIZE, NUM_HEADS, CONTEXT_SIZE, DROPOUT)\n",
    "m = model.to(DEVICE)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a155023",
   "metadata": {
    "papermill": {
     "duration": 0.004281,
     "end_time": "2024-05-14T15:43:45.031640",
     "exception": false,
     "start_time": "2024-05-14T15:43:45.027359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 592212,
     "sourceId": 1067156,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 39748,
     "sourceId": 47475,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.27679,
   "end_time": "2024-05-14T15:43:46.161173",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-14T15:43:28.884383",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
