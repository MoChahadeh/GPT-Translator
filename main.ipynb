{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e92181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:44.509222Z",
     "iopub.status.busy": "2024-05-14T18:55:44.508700Z",
     "iopub.status.idle": "2024-05-14T18:55:49.170435Z",
     "shell.execute_reply": "2024-05-14T18:55:49.169120Z"
    },
    "papermill": {
     "duration": 4.67139,
     "end_time": "2024-05-14T18:55:49.172898",
     "exception": false,
     "start_time": "2024-05-14T18:55:44.501508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c73ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:49.184704Z",
     "iopub.status.busy": "2024-05-14T18:55:49.184191Z",
     "iopub.status.idle": "2024-05-14T18:55:49.190461Z",
     "shell.execute_reply": "2024-05-14T18:55:49.189308Z"
    },
    "papermill": {
     "duration": 0.015533,
     "end_time": "2024-05-14T18:55:49.193611",
     "exception": false,
     "start_time": "2024-05-14T18:55:49.178078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "CONTEXT_SIZE = 256\n",
    "TRANSFORMER_COUNT = 6\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08782b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:49.205723Z",
     "iopub.status.busy": "2024-05-14T18:55:49.205344Z",
     "iopub.status.idle": "2024-05-14T18:55:49.787444Z",
     "shell.execute_reply": "2024-05-14T18:55:49.786299Z"
    },
    "papermill": {
     "duration": 0.591525,
     "end_time": "2024-05-14T18:55:49.790631",
     "exception": false,
     "start_time": "2024-05-14T18:55:49.199106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours !\n",
       "2                    Run!               Courez !\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             Ça alors !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f94d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:49.805616Z",
     "iopub.status.busy": "2024-05-14T18:55:49.803350Z",
     "iopub.status.idle": "2024-05-14T18:55:50.822283Z",
     "shell.execute_reply": "2024-05-14T18:55:50.820830Z"
    },
    "papermill": {
     "duration": 1.02826,
     "end_time": "2024-05-14T18:55:50.824728",
     "exception": false,
     "start_time": "2024-05-14T18:55:49.796468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi.', 'run!', 'run!', 'who?', 'wow!']\n",
      "['salut!', 'cours!', 'courez!', 'qui ?', 'ça alors!']\n"
     ]
    }
   ],
   "source": [
    "english_all = df[\"English words/sentences\"].values.astype(str)\n",
    "french_all = df[\"French words/sentences\"].values.astype(str)\n",
    "\n",
    "english_all = [seq.replace(\"\\u202f\", \"\") for seq in english_all]\n",
    "french_all = [seq.replace(\"\\u202f\", \"\") for seq in french_all]\n",
    "\n",
    "english_all = [seq.lower() for seq in english_all]\n",
    "french_all = [seq.lower() for seq in french_all]\n",
    "\n",
    "print(english_all[0:5])\n",
    "print(french_all[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfce10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:50.837369Z",
     "iopub.status.busy": "2024-05-14T18:55:50.836921Z",
     "iopub.status.idle": "2024-05-14T18:55:50.884229Z",
     "shell.execute_reply": "2024-05-14T18:55:50.883338Z"
    },
    "papermill": {
     "duration": 0.056524,
     "end_time": "2024-05-14T18:55:50.886665",
     "exception": false,
     "start_time": "2024-05-14T18:55:50.830141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding token ID for english: -1\n",
      "Padding token ID for frencb: -1\n",
      "EN Vocab Size:  10000\n",
      "FR Vocab Size:  10000\n"
     ]
    }
   ],
   "source": [
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"/kaggle/input/french-english-tokenization/other/100embed/1/en.wiki.bpe.vs10000.model\")\n",
    "\n",
    "sp_fr = spm.SentencePieceProcessor()\n",
    "sp_fr.load(\"/kaggle/input/french-english-tokenization/other/100embed/1/fr.wiki.bpe.vs10000.model\")\n",
    "\n",
    "en_vocab = sp_en.get_piece_size()\n",
    "fr_vocab = sp_fr.get_piece_size()\n",
    "\n",
    "padding_token_id_en = sp_en.pad_id()\n",
    "print(\"Padding token ID for english:\", padding_token_id_en)\n",
    "\n",
    "padding_token_id_fr = sp_fr.pad_id()\n",
    "print(\"Padding token ID for frencb:\", padding_token_id_fr)\n",
    "\n",
    "\n",
    "print(\"EN Vocab Size: \", en_vocab)\n",
    "print(\"FR Vocab Size: \", fr_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a238f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:55:50.899689Z",
     "iopub.status.busy": "2024-05-14T18:55:50.898619Z",
     "iopub.status.idle": "2024-05-14T18:56:00.512916Z",
     "shell.execute_reply": "2024-05-14T18:56:00.511908Z"
    },
    "papermill": {
     "duration": 9.623188,
     "end_time": "2024-05-14T18:56:00.515246",
     "exception": false,
     "start_time": "2024-05-14T18:55:50.892058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 40, 9916, 9935, 2], [1, 888, 9960, 2], [1, 888, 9960, 2], [1, 305, 9967, 2], [1, 15, 90, 9960, 2]]\n",
      "[[1, 1021, 138, 9977, 2], [1, 926, 9977, 2], [1, 844, 6607, 9977, 2], [1, 135, 2340, 2], [1, 9558, 494, 9977, 2]]\n"
     ]
    }
   ],
   "source": [
    "english_data = [sp_en.encode_as_ids(seq) for seq in english_all]\n",
    "french_data = [sp_fr.encode_as_ids(seq) for seq in french_all]\n",
    "\n",
    "english_data = [[sp_en.piece_to_id(\"<s>\")] + seq + [sp_en.piece_to_id(\"</s>\")] for seq in english_data]\n",
    "french_data = [[sp_fr.piece_to_id(\"<s>\")] + seq + [sp_fr.piece_to_id(\"</s>\")] for seq in french_data]\n",
    "\n",
    "print(english_data[0:5])\n",
    "print(french_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0c08c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.528999Z",
     "iopub.status.busy": "2024-05-14T18:56:00.527755Z",
     "iopub.status.idle": "2024-05-14T18:56:00.538876Z",
     "shell.execute_reply": "2024-05-14T18:56:00.537353Z"
    },
    "papermill": {
     "duration": 0.02078,
     "end_time": "2024-05-14T18:56:00.541702",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.520922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Single Attention Head\n",
    "class SingleHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, head_size, context_size:int, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(emb_size, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, masked=True, cross=None):\n",
    "        B,T, C = x.shape\n",
    "        \n",
    "        if cross is None:\n",
    "            k = self.key(x)   # Size (B, T, head_size)\n",
    "            v = self.value(x) # same thing..\n",
    "        else:\n",
    "            k = cross.detach().clone()\n",
    "            v = cross.detach().clone()\n",
    "            \n",
    "        \n",
    "        q = self.query(x) # same thing..\n",
    "        \n",
    "        weight = q @ k.transpose(-2, -1) * (k.shape[-1]**-0.5) # this equation is defined in the original paper and the multiplication part is normalization over each Time Serie in the batch.\n",
    "        if(masked): weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) # This will mask the upper triangle of zeros and turn it into -inf for the softmax func\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        weight = self.dropout(weight)\n",
    "        \n",
    "        out = weight @ v\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257341e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.554288Z",
     "iopub.status.busy": "2024-05-14T18:56:00.553871Z",
     "iopub.status.idle": "2024-05-14T18:56:00.563203Z",
     "shell.execute_reply": "2024-05-14T18:56:00.561935Z"
    },
    "papermill": {
     "duration": 0.018233,
     "end_time": "2024-05-14T18:56:00.565444",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.547211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, num_heads, head_size, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.heads = nn.ModuleList([SingleHeadedAttention(embed_size,head_size, context_size, dropout) for _ in range(num_heads)])\n",
    "        self.linear = nn.Linear(head_size*num_heads, embed_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, masked=True, cross=None):\n",
    "#         if cross is not None:\n",
    "#             B, T, _ = cross.shape\n",
    "#             cross = cross.view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        out = torch.cat([h(x, masked, cross[:, :, i*self.head_size:(i+1)*self.head_size] if cross is not None else None) for i, h in enumerate(self.heads)], dim=-1)\n",
    "\n",
    "        out = self.linear(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dd69c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.578772Z",
     "iopub.status.busy": "2024-05-14T18:56:00.577687Z",
     "iopub.status.idle": "2024-05-14T18:56:00.584375Z",
     "shell.execute_reply": "2024-05-14T18:56:00.583511Z"
    },
    "papermill": {
     "duration": 0.015762,
     "end_time": "2024-05-14T18:56:00.586724",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.570962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Linear(emb_size, emb_size*4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(emb_size*4, emb_size),\n",
    "        nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd262378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.599731Z",
     "iopub.status.busy": "2024-05-14T18:56:00.598968Z",
     "iopub.status.idle": "2024-05-14T18:56:00.606401Z",
     "shell.execute_reply": "2024-05-14T18:56:00.605513Z"
    },
    "papermill": {
     "duration": 0.016616,
     "end_time": "2024-05-14T18:56:00.608741",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.592125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderTransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        head_size = embed_size // num_heads\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_norm1 = self.norm1(x)\n",
    "        x = x + self.attention(x_norm1, masked=True)\n",
    "        x_norm2 = self.norm2(x)\n",
    "        x = x + self.ff(x_norm2)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb120b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.622666Z",
     "iopub.status.busy": "2024-05-14T18:56:00.621805Z",
     "iopub.status.idle": "2024-05-14T18:56:00.631721Z",
     "shell.execute_reply": "2024-05-14T18:56:00.630314Z"
    },
    "papermill": {
     "duration": 0.020232,
     "end_time": "2024-05-14T18:56:00.634472",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.614240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        head_size = embed_size // num_heads\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.self_attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.cross_attention = MultiHeadedAttention(embed_size, num_heads, head_size, context_size, dropout)\n",
    "        self.norm3 = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        decoder_input, encoder_output = x\n",
    "        dec_norm1 = self.norm1(decoder_input)\n",
    "        self_atten_out = self.self_attention(dec_norm1)\n",
    "        dec_out_1 = decoder_input + self_atten_out\n",
    "        \n",
    "        dec_norm_2 = self.norm2(dec_out_1)\n",
    "        cross_atten_out = self.cross_attention(dec_norm_2, masked=False, cross=encoder_output)\n",
    "        dec_out_2 = dec_out_1 + cross_atten_out\n",
    "        \n",
    "        dec_out = dec_out_2 + self.ff(dec_out_2)\n",
    "        \n",
    "        return dec_out, encoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "354c8965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.647488Z",
     "iopub.status.busy": "2024-05-14T18:56:00.646778Z",
     "iopub.status.idle": "2024-05-14T18:56:00.654358Z",
     "shell.execute_reply": "2024-05-14T18:56:00.653415Z"
    },
    "papermill": {
     "duration": 0.016662,
     "end_time": "2024-05-14T18:56:00.656654",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.639992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,transformer_count , vocab_size, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.transformers = nn.Sequential(*[EncoderTransformerBlock(embed_size, num_heads, context_size, dropout=0.2) for _ in range(transformer_count)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        \n",
    "        tk_emb = self.token_embed(x)\n",
    "        pos_emb = self.pos_embed(x)\n",
    "        \n",
    "        x = tk_emb + pos_emb\n",
    "#         print(\"encoder embedding shape: \", x.shape)\n",
    "        x = self.transformers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b19300a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.670115Z",
     "iopub.status.busy": "2024-05-14T18:56:00.669697Z",
     "iopub.status.idle": "2024-05-14T18:56:00.677411Z",
     "shell.execute_reply": "2024-05-14T18:56:00.676433Z"
    },
    "papermill": {
     "duration": 0.017923,
     "end_time": "2024-05-14T18:56:00.679876",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.661953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, transformer_count, vocab_size, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.transformers = nn.Sequential(*[DecoderTransformerBlock(embed_size, num_heads, context_size, dropout) for _ in range(transformer_count)])\n",
    "    \n",
    "    def forward(self, decoder_input, encoder_output):\n",
    "        \n",
    "        B, T = decoder_input.shape\n",
    "        \n",
    "        tk_emb = self.token_embed(decoder_input)\n",
    "        pos_emb = self.pos_embed(decoder_input)\n",
    "        \n",
    "        x = tk_emb + pos_emb\n",
    "#         print(\"decoder embedding shape: \", x.shape)\n",
    "        x,_ = self.transformers((x, encoder_output))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db21103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.693005Z",
     "iopub.status.busy": "2024-05-14T18:56:00.692353Z",
     "iopub.status.idle": "2024-05-14T18:56:00.702625Z",
     "shell.execute_reply": "2024-05-14T18:56:00.701704Z"
    },
    "papermill": {
     "duration": 0.019612,
     "end_time": "2024-05-14T18:56:00.705053",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.685441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FrenchEnglishTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, transformer_count , vocab_size_en, vocab_size_fr, embed_size, num_heads, context_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(transformer_count, vocab_size_fr, embed_size, num_heads, context_size, dropout)\n",
    "        self.decoder = Decoder(transformer_count, vocab_size_en, embed_size, num_heads, context_size, dropout)\n",
    "        self.norm_final = nn.LayerNorm(embed_size)\n",
    "        self.linear_final = nn.Linear(embed_size, vocab_size_en)\n",
    "        \n",
    "    def forward(self, french, english, target_english=None):\n",
    "        \n",
    "        encoder_out = self.encoder(french)\n",
    "        decoder_out = self.decoder(english, encoder_out)\n",
    "        \n",
    "        out = self.norm_final(decoder_out)\n",
    "        out = self.linear_final(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def translate(self, idx, gen_length, context_size:int, sp_en, sp_fr):\n",
    "            \n",
    "        initial_english = torch.tensor([[sp_en.piece_to_id(\"<s>\")]], dtype=torch.long)\n",
    "        initial_english = initial_english.to(DEVICE)\n",
    "        print(initial_english)\n",
    "        for _ in range(gen_length):\n",
    "            \n",
    "            idx_cropped = idx[:, -context_size:] if len(idx[0]) > context_size else idx\n",
    "            \n",
    "            logits = self(idx_cropped, initial_english)\n",
    "            logits = logits[:, -1, :]\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ad5638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:00.718121Z",
     "iopub.status.busy": "2024-05-14T18:56:00.717709Z",
     "iopub.status.idle": "2024-05-14T18:56:01.004534Z",
     "shell.execute_reply": "2024-05-14T18:56:01.003041Z"
    },
    "papermill": {
     "duration": 0.296164,
     "end_time": "2024-05-14T18:56:01.006883",
     "exception": false,
     "start_time": "2024-05-14T18:56:00.710719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.180432 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = FrenchEnglishTransformer(TRANSFORMER_COUNT, en_vocab, fr_vocab, EMBEDDING_SIZE, NUM_HEADS, CONTEXT_SIZE, DROPOUT)\n",
    "m = model.to(DEVICE)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e805e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T18:56:01.019977Z",
     "iopub.status.busy": "2024-05-14T18:56:01.019537Z",
     "iopub.status.idle": "2024-05-14T18:56:05.863186Z",
     "shell.execute_reply": "2024-05-14T18:56:05.862264Z"
    },
    "papermill": {
     "duration": 4.853135,
     "end_time": "2024-05-14T18:56:05.865488",
     "exception": false,
     "start_time": "2024-05-14T18:56:01.012353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n",
      " ⁇  (0000) slow religious touchdown worth hospital mas queensuble donald chancellorvir punk writer observations memor maа unstream course circularign expansteen good accom culenh ref programmes th nev entirely whomodoreot benefitsski virtualcesarmhis socía fu baker conqu × files article monte streets otherwisevisionben ivanroy grove actingame its gil... helen chinese jos ts punk eug starred elizeleyonda segment cons basesmiss planning pier maxulus herbert floureuí frequency polynyle tiesger antiquä liver color anat tries certific bbciter\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n",
    "print(sp_en.decode_ids(m.translate(context, 100, CONTEXT_SIZE, sp_en, sp_fr)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1d4c1",
   "metadata": {
    "papermill": {
     "duration": 0.005781,
     "end_time": "2024-05-14T18:56:05.877420",
     "exception": false,
     "start_time": "2024-05-14T18:56:05.871639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 592212,
     "sourceId": 1067156,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 39748,
     "sourceId": 47475,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.413836,
   "end_time": "2024-05-14T18:56:07.006462",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-14T18:55:41.592626",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
